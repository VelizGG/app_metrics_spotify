{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25cd9ad5",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# Custom modules\n",
    "from models import (\n",
    "    prepare_skip_prediction_data,\n",
    "    train_logistic_regression,\n",
    "    train_random_forest,\n",
    "    calculate_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_feature_importance\n",
    ")\n",
    "\n",
    "# Config\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì M√≥dulos importados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db303314",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712eee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos con features\n",
    "data_path = Path('../data/features/listening_history_with_features.parquet')\n",
    "\n",
    "if not data_path.exists():\n",
    "    print(\"‚ö†Ô∏è Ejecutar notebook 02_feature_engineering primero\")\n",
    "    data_path = Path('../data/demo/synthetic_spotify_data.parquet')\n",
    "\n",
    "df = pd.read_parquet(data_path)\n",
    "print(f\"‚úì Datos cargados: {df.shape}\")\n",
    "print(f\"\\nColumnas disponibles:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba5910",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio de Target\n",
    "\n",
    "Entender la distribuci√≥n de la variable objetivo (skipped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3309ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n del target\n",
    "skip_counts = df['skipped'].value_counts()\n",
    "skip_pct = df['skipped'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"=== DISTRIBUCI√ìN DEL TARGET ===\")\n",
    "print(f\"\\nSkipped:\")\n",
    "print(skip_counts)\n",
    "print(f\"\\nPorcentajes:\")\n",
    "print(skip_pct)\n",
    "\n",
    "# Visualizar\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=['No Skip', 'Skip'],\n",
    "        y=[skip_counts.get(False, 0), skip_counts.get(True, 0)],\n",
    "        text=[f\"{skip_pct.get(False, 0):.1f}%\", f\"{skip_pct.get(True, 0):.1f}%\"],\n",
    "        textposition='auto',\n",
    "        marker_color=['#1DB954', '#FF6B6B']\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Distribuci√≥n de Variable Target: Skipped',\n",
    "    xaxis_title='Estado',\n",
    "    yaxis_title='Cantidad',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "skip_rate = skip_pct.get(True, 0)\n",
    "if skip_rate < 10 or skip_rate > 90:\n",
    "    print(f\"\\n‚ö†Ô∏è ALERTA: Desbalance de clases detectado ({skip_rate:.1f}% skips)\")\n",
    "    print(\"   Considerar t√©cnicas de balanceo (SMOTE, class weights, etc.)\")\n",
    "else:\n",
    "    print(f\"\\n‚úì Balance de clases aceptable ({skip_rate:.1f}% skips)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d39ed77",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering para ML\n",
    "\n",
    "Preparar features predictivos:\n",
    "- Metadata del track (duraci√≥n, artista, album)\n",
    "- Contexto temporal (hora, d√≠a de semana, posici√≥n en sesi√≥n)\n",
    "- Historial (tracks previos, patrones de skip)\n",
    "- One-hot encoding para variables categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3880d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para ML\n",
    "X, y, feature_names, scaler, encoder = prepare_skip_prediction_data(df.copy())\n",
    "\n",
    "print(f\"‚úì Datos preparados para ML\")\n",
    "print(f\"\\nShape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"N√∫mero de features: {len(feature_names)}\")\n",
    "print(f\"\\nPrimeras 10 features:\")\n",
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c49bbf",
   "metadata": {},
   "source": [
    "## 5. Train/Test Split\n",
    "\n",
    "Divisi√≥n estratificada para mantener proporci√≥n de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c66db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(f\"‚úì Datos divididos:\")\n",
    "print(f\"  Train: {X_train.shape} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:  {X_test.shape} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nDistribuci√≥n del target en train:\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True))\n",
    "print(f\"\\nDistribuci√≥n del target en test:\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb998f",
   "metadata": {},
   "source": [
    "## 6. Modelo Baseline: Logistic Regression\n",
    "\n",
    "Modelo simple y r√°pido como baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e17437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Logistic Regression\n",
    "lr_model, lr_metrics = train_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"=== LOGISTIC REGRESSION - RESULTADOS ===\\n\")\n",
    "for metric, value in lr_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "print(\"\\n\" + classification_report(y_test, y_pred_lr, target_names=['No Skip', 'Skip']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7115800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Logistic Regression\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "plot_confusion_matrix(cm_lr, labels=['No Skip', 'Skip'], title='Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689b547",
   "metadata": {},
   "source": [
    "## 7. Modelo Avanzado: Random Forest\n",
    "\n",
    "Modelo ensemble para capturar relaciones no lineales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee187660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest\n",
    "rf_model, rf_metrics = train_random_forest(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"=== RANDOM FOREST - RESULTADOS ===\\n\")\n",
    "for metric, value in rf_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\n\" + classification_report(y_test, y_pred_rf, target_names=['No Skip', 'Skip']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd86172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - Random Forest\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "plot_confusion_matrix(cm_rf, labels=['No Skip', 'Skip'], title='Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce3b48",
   "metadata": {},
   "source": [
    "## 8. Comparaci√≥n de Modelos\n",
    "\n",
    "Comparar performance de ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43359da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar m√©tricas\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Logistic Regression': lr_metrics,\n",
    "    'Random Forest': rf_metrics\n",
    "}).T\n",
    "\n",
    "print(\"=== COMPARACI√ìN DE MODELOS ===\\n\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualizar\n",
    "fig = go.Figure()\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Logistic Regression',\n",
    "    x=metrics,\n",
    "    y=[lr_metrics[m] for m in metrics],\n",
    "    text=[f\"{lr_metrics[m]:.3f}\" for m in metrics],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Random Forest',\n",
    "    x=metrics,\n",
    "    y=[rf_metrics[m] for m in metrics],\n",
    "    text=[f\"{rf_metrics[m]:.3f}\" for m in metrics],\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comparaci√≥n de M√©tricas: LR vs RF',\n",
    "    xaxis_title='M√©trica',\n",
    "    yaxis_title='Score',\n",
    "    yaxis_range=[0, 1],\n",
    "    barmode='group',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Determinar mejor modelo\n",
    "best_model_name = 'Random Forest' if rf_metrics['roc_auc'] > lr_metrics['roc_auc'] else 'Logistic Regression'\n",
    "print(f\"\\nüèÜ Mejor modelo: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3fed03",
   "metadata": {},
   "source": [
    "## 9. Curvas ROC\n",
    "\n",
    "Analizar trade-off entre TPR y FPR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "fig = go.Figure()\n",
    "\n",
    "# Logistic Regression\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_proba_lr)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr_lr, y=tpr_lr,\n",
    "    mode='lines',\n",
    "    name=f'Logistic Regression (AUC = {lr_metrics[\"roc_auc\"]:.3f})',\n",
    "    line=dict(width=2)\n",
    "))\n",
    "\n",
    "# Random Forest\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_rf)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr_rf, y=tpr_rf,\n",
    "    mode='lines',\n",
    "    name=f'Random Forest (AUC = {rf_metrics[\"roc_auc\"]:.3f})',\n",
    "    line=dict(width=2)\n",
    "))\n",
    "\n",
    "# L√≠nea diagonal (random classifier)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1], y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random Classifier',\n",
    "    line=dict(dash='dash', color='gray')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC Curves Comparison',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    height=500,\n",
    "    legend=dict(x=0.6, y=0.1)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb64247",
   "metadata": {},
   "source": [
    "## 10. Feature Importance (Random Forest)\n",
    "\n",
    "Identificar features m√°s predictivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d02930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=== TOP 15 FEATURES M√ÅS IMPORTANTES ===\\n\")\n",
    "print(feature_importance_df.head(15))\n",
    "\n",
    "# Visualizar\n",
    "fig = px.bar(\n",
    "    feature_importance_df.head(20),\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    orientation='h',\n",
    "    title='Top 20 Features - Random Forest',\n",
    "    labels={'importance': 'Importancia', 'feature': 'Feature'}\n",
    ")\n",
    "fig.update_layout(height=600, yaxis={'categoryorder': 'total ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7a4ae",
   "metadata": {},
   "source": [
    "## 11. An√°lisis de Errores\n",
    "\n",
    "Investigar casos donde el modelo falla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casos mal clasificados\n",
    "y_pred_best = rf_model.predict(X_test)\n",
    "errors_idx = np.where(y_pred_best != y_test)[0]\n",
    "\n",
    "print(f\"=== AN√ÅLISIS DE ERRORES ===\")\n",
    "print(f\"\\nTotal errores: {len(errors_idx)} de {len(y_test)} ({len(errors_idx)/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# Tipo de errores\n",
    "false_positives = np.sum((y_pred_best == 1) & (y_test == 0))\n",
    "false_negatives = np.sum((y_pred_best == 0) & (y_test == 1))\n",
    "\n",
    "print(f\"\\nFalsos Positivos (predijo skip, no skippe√≥): {false_positives}\")\n",
    "print(f\"Falsos Negativos (predijo no skip, skippe√≥): {false_negatives}\")\n",
    "\n",
    "# Analizar probabilidades de predicci√≥n en errores\n",
    "if len(errors_idx) > 0:\n",
    "    error_probas = y_pred_proba_rf[errors_idx]\n",
    "    print(f\"\\nConfianza del modelo en errores:\")\n",
    "    print(f\"  Media: {error_probas.mean():.3f}\")\n",
    "    print(f\"  Min: {error_probas.min():.3f}\")\n",
    "    print(f\"  Max: {error_probas.max():.3f}\")\n",
    "    \n",
    "    # Histograma de probabilidades en errores\n",
    "    fig = px.histogram(\n",
    "        error_probas,\n",
    "        nbins=20,\n",
    "        title='Distribuci√≥n de Probabilidades en Predicciones Err√≥neas',\n",
    "        labels={'value': 'Probabilidad de Skip', 'count': 'Frecuencia'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f86b6a",
   "metadata": {},
   "source": [
    "## 12. Exportar Modelo\n",
    "\n",
    "Guardar modelo entrenado para producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c67cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Crear directorio\n",
    "models_dir = Path('../models')\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Guardar mejor modelo\n",
    "joblib.dump(rf_model, models_dir / 'skip_prediction_rf.pkl')\n",
    "joblib.dump(scaler, models_dir / 'scaler.pkl')\n",
    "joblib.dump(encoder, models_dir / 'encoder.pkl')\n",
    "\n",
    "# Guardar feature names\n",
    "with open(models_dir / 'feature_names.txt', 'w') as f:\n",
    "    f.write('\\n'.join(feature_names))\n",
    "\n",
    "print(\"‚úì Modelo exportado:\")\n",
    "print(f\"  - {models_dir / 'skip_prediction_rf.pkl'}\")\n",
    "print(f\"  - {models_dir / 'scaler.pkl'}\")\n",
    "print(f\"  - {models_dir / 'encoder.pkl'}\")\n",
    "print(f\"  - {models_dir / 'feature_names.txt'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff14458b",
   "metadata": {},
   "source": [
    "## 13. Conclusiones & Next Steps\n",
    "\n",
    "### Resultados del Modelo\n",
    "\n",
    "**Mejor Modelo:** Random Forest\n",
    "- **Accuracy:** {rf_metrics['accuracy']:.3f}\n",
    "- **Precision:** {rf_metrics['precision']:.3f}\n",
    "- **Recall:** {rf_metrics['recall']:.3f}\n",
    "- **F1-Score:** {rf_metrics['f1']:.3f}\n",
    "- **ROC-AUC:** {rf_metrics['roc_auc']:.3f}\n",
    "\n",
    "### Features Clave\n",
    "\n",
    "Los 5 features m√°s importantes:\n",
    "1. [Top feature del an√°lisis]\n",
    "2. [...]\n",
    "\n",
    "### Insights de Negocio\n",
    "\n",
    "- Skip rate var√≠a significativamente por [contexto/hora/etc]\n",
    "- [Otros insights basados en feature importance]\n",
    "\n",
    "### Pr√≥ximos Pasos\n",
    "\n",
    "1. ‚úÖ **Hyperparameter Tuning**: GridSearch/RandomSearch para optimizar RF\n",
    "2. ‚úÖ **Modelos Avanzados**: XGBoost, LightGBM\n",
    "3. ‚úÖ **Ensemble Methods**: Stacking de m√∫ltiples modelos\n",
    "4. ‚úÖ **Feature Engineering**: Crear features m√°s sofisticados\n",
    "5. ‚úÖ **Deploy**: API REST para servir predicciones en producci√≥n\n",
    "\n",
    "### Deployment Considerations\n",
    "\n",
    "- **Latencia**: Random Forest permite inferencia r√°pida (<10ms)\n",
    "- **Monitoring**: Trackear drift en features y performance metrics\n",
    "- **Retraining**: Pipeline automatizado para reentrenar mensualmente\n",
    "- **A/B Testing**: Validar impacto en m√©tricas de negocio\n",
    "\n",
    "---\n",
    "\n",
    "**Este notebook demuestra:**\n",
    "- End-to-end ML pipeline\n",
    "- Model selection & evaluation\n",
    "- Production-ready code\n",
    "- Business-focused insights"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
